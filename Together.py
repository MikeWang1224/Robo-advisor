# -*- coding: utf-8 -*-
"""
å…‰å¯¶ç§‘æ–°èæŠ“å–ç¨‹å¼ï¼ˆYahoo Financeï¼‰
ç‰ˆæœ¬ï¼šLiteon-Yahoo v1
-----------------------------------
âœ” æŠ“å…‰å¯¶ç§‘ Yahoo æ–°èï¼ˆ36 å°æ™‚å…§ï¼‰
âœ” Firestore ä¸Šå‚³
âœ” HuggingFace å…è²» Embedding
"""

import os
import time
import json
import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup, XMLParsedAsHTMLWarning
import warnings
import firebase_admin
from firebase_admin import credentials, firestore

warnings.filterwarnings("ignore", category=XMLParsedAsHTMLWarning)

# ---------------------- è¨­å®š ---------------------- #
HEADERS = {'User-Agent': 'Mozilla/5.0'}

HF_API_URL = "https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2"
HF_TOKEN = os.environ.get("HF_TOKEN")

if not HF_TOKEN:
    raise ValueError("âš ï¸ æ‰¾ä¸åˆ° HF_TOKENï¼Œè«‹åœ¨ GitHub Secrets è¨­å®šï¼")

HF_HEADERS = {
    "Authorization": f"Bearer {HF_TOKEN}"
}

# Firestore åˆå§‹åŒ–
key_dict = json.loads(os.environ["NEW_FIREBASE_KEY"])
cred = credentials.Certificate(key_dict)
firebase_admin.initialize_app(cred)
db = firestore.client()

# ---------------------- æ™‚é–“éæ¿¾ ---------------------- #
def is_recent(published_time, hours=36):
    now = datetime.now().astimezone()
    return (now - published_time) <= timedelta(hours=hours)

# ---------------------- æŠ“ Yahoo æ–‡ç« å…§å®¹ ---------------------- #
def fetch_article_content(url):
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        paragraphs = soup.select('article p') or soup.select('p')

        text = '\n'.join([p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 40])
        return text[:1500] + ('...' if len(text) > 1500 else '')
    except:
        return "ç„¡æ³•å–å¾—æ–°èå…§å®¹"

# ---------------------- HuggingFace Embedding ---------------------- #
def generate_embedding(text):
    if not text:
        return []
    try:
        res = requests.post(
            HF_API_URL,
            headers=HF_HEADERS,
            json={"inputs": text[:1000]},
            timeout=20
        )
        data = res.json()
        if isinstance(data, list):
            return data
    except:
        pass
    return []

# ---------------------- Yahoo æœå°‹å…‰å¯¶ç§‘ ---------------------- #
def fetch_yahoo_liteon(limit=30):
    print("\nğŸ“¡ Yahooï¼šå…‰å¯¶ç§‘")
    keyword = "å…‰å¯¶ç§‘"
    base = "https://tw.stock.yahoo.com"
    url = f"{base}/search?p={keyword}&sort=time"

    news_list, seen = [], set()

    try:
        r = requests.get(url, headers=HEADERS)
        soup = BeautifulSoup(r.text, 'html.parser')
        links = soup.select('a.js-content-viewer') or soup.select('h3 a')

        for a in links:
            if len(news_list) >= limit:
                break

            title = a.get_text(strip=True)
            if not title or title in seen:
                continue
            seen.add(title)

            href = a.get("href")
            if href and not href.startswith("http"):
                href = base + href

            # æŠ“æ–‡ç« å…§å®¹
            content = fetch_article_content(href)

            # æŠ“ç™¼ä½ˆæ™‚é–“
            try:
                r2 = requests.get(href, headers=HEADERS)
                s2 = BeautifulSoup(r2.text, 'html.parser')
                time_tag = s2.find("time")

                if not time_tag or not time_tag.has_attr("datetime"):
                    continue

                published_dt = datetime.fromisoformat(
                    time_tag["datetime"].replace("Z", "+00:00")
                ).astimezone()

                if not is_recent(published_dt):
                    continue

            except:
                continue

            news_list.append({
                'title': title,
                'content': content,
                'published_time': published_dt
            })

    except:
        pass

    return news_list

# ---------------------- Firestore å„²å­˜ ---------------------- #
def save_news_to_firestore(news_list):
    if not news_list:
        print("âš ï¸ ç„¡å…‰å¯¶ç§‘æ–°èå¯å¯«å…¥ Firebase")
        return

    doc_id = datetime.now().strftime("%Y%m%d")
    ref = db.collection("NEWS_Liteon").document(doc_id)

    data = {}
    for i, n in enumerate(news_list, 1):
        emb = generate_embedding(n["content"])
        data[f"news_{i}"] = {
            "title": n["title"],
            "content": n["content"],
            "embedding": emb,
            "published_time": n["published_time"].strftime("%Y-%m-%d %H:%M")
        }

    ref.set(data)
    print(f"âœ… Firestore å„²å­˜å®Œæˆï¼šNEWS_Liteon/{doc_id}")

# ---------------------- ä¸»ç¨‹å¼ ---------------------- #
if __name__ == "__main__":
    liteon_news = fetch_yahoo_liteon(30)
    save_news_to_firestore(liteon_news)
    print("\nğŸ‰ å…‰å¯¶ç§‘ Yahoo æ–°èæŠ“å–å®Œæˆï¼")
