# -*- coding: utf-8 -*-
"""
å…‰å¯¶ç§‘æ–°èæŠ“å–ï¼ˆYahoo å¼·åŒ–ç‰ˆï¼‰
âœ” å¤šé—œéµå­—ï¼šå…‰å¯¶ç§‘ / å…‰å¯¶ / 2301
âœ” æŠ“å¤šé ï¼špage=1~3
âœ” æ–°ç‰ˆï¼‹èˆŠç‰ˆ Yahoo åŒæ™‚æ”¯æ´
âœ” æŠ“æ–°èå…¨æ–‡
âœ” æ™‚é–“ï¼š36 å°æ™‚å…§
âœ” å¯«å…¥ Firestoreï¼ˆä¸å«è‚¡åƒ¹ï¼‰
"""

import os
import time
import requests
from datetime import datetime, timedelta, timezone
from bs4 import BeautifulSoup
import firebase_admin
from firebase_admin import credentials, firestore

# -----------------------------
# Firestore åˆå§‹åŒ–
# -----------------------------
if not firebase_admin._apps:
    cred = credentials.Certificate(os.environ["GOOGLE_APPLICATION_CREDENTIALS"])
    firebase_admin.initialize_app(cred)

db = firestore.client()
COLL_NAME = "NEWS_LiteOn"
KEYWORDS = ["å…‰å¯¶ç§‘", "å…‰å¯¶", "2301"]
MAX_HOURS = 36
HEADERS = {"User-Agent": "Mozilla/5.0"}

# -----------------------------
# æ™‚é–“éæ¿¾
# -----------------------------
def is_recent(dt):
    return (datetime.now(timezone.utc) - dt).total_seconds() <= MAX_HOURS * 3600

# -----------------------------
# Yahoo æŠ“å–ï¼ˆå¼·åŒ–ï¼‰
# -----------------------------
def fetch_yahoo_multi(limit_each=30):
    print("\nğŸ“¡ Yahoo æœå°‹å¼·åŒ–ç‰ˆ")

    base = "https://tw.news.yahoo.com"
    all_news, seen_links = [], set()

    for keyword in KEYWORDS:
        print(f"\nğŸ” é—œéµå­—ï¼š{keyword}")

        for page in range(1, 4):  # æŠ“ 3 é 
            url = f"{base}/search?p={keyword}&sort=time&b={(page-1)*10+1}"

            try:
                r = requests.get(url, headers=HEADERS, timeout=10)
                soup = BeautifulSoup(r.text, "html.parser")

                # æ–°ç‰ˆ Yahoo
                links = soup.select("a.js-content-viewer")

                # èˆŠç‰ˆ Yahoo Fallback
                if not links:
                    links = soup.select("h3 a")

                for a in links:
                    href = a.get("href")
                    if not href:
                        continue
                    if not href.startswith("http"):
                        href = base + href
                    if href in seen_links:
                        continue
                    seen_links.add(href)

                    # æŠ“å…§æ–‡
                    try:
                        r2 = requests.get(href, headers=HEADERS, timeout=10)
                        s2 = BeautifulSoup(r2.text, "html.parser")

                        title = s2.find("h1")
                        if not title:
                            continue
                        title = title.get_text(strip=True)

                        paras = s2.select("article p") or s2.select("p")
                        content = "\n".join(
                            p.get_text(strip=True)
                            for p in paras
                            if len(p.get_text(strip=True)) > 40
                        )[:1500]

                        time_tag = s2.find("time")
                        if not time_tag or not time_tag.has_attr("datetime"):
                            continue

                        published_dt = datetime.fromisoformat(
                            time_tag["datetime"].replace("Z", "+00:00")
                        )
                        if not is_recent(published_dt):
                            continue

                        all_news.append({
                            "title": title,
                            "content": content,
                            "time": published_dt.strftime("%Y-%m-%d %H:%M"),
                            "source": "Yahoo"
                        })

                        time.sleep(0.3)

                    except Exception:
                        continue

            except Exception:
                continue

    return all_news


# -----------------------------
# Firestore å¯«å…¥
# -----------------------------
def save_news(news_list):
    if not news_list:
        print("âš ï¸ æ²’æœ‰æ–°èå¯å¯«å…¥")
        return

    today = datetime.now().strftime("%Y%m%d")
    ref = db.collection(COLL_NAME).document(today)

    data = {}
    for i, n in enumerate(news_list, 1):
        data[f"news_{i}"] = n

    ref.set(data)
    print(f"ğŸ”¥ Firestore å·²å¯«å…¥ â†’ {COLL_NAME}/{today}")
    print(f"ğŸ“¦ å…± {len(news_list)} å‰‡æ–°è")

# -----------------------------
# ä¸»ç¨‹å¼
# -----------------------------
if __name__ == "__main__":
    all_news = fetch_yahoo_multi()
    save_news(all_news)
    print("\nğŸ‰ Yahoo æ–°èæŠ“å–å®Œæˆï¼ˆå¼·åŒ–ç‰ˆï¼‰ï¼")
