# -*- coding: utf-8 -*-
"""
å…‰å¯¶ç§‘è‚¡å¸‚æ–°èæŠ“å–ï¼ˆYahoo è‚¡å¸‚æ–°èé é¢ï¼‰
æ¢ä»¶ï¼š
âœ” 3 å¤©å…§ï¼ˆ72 å°æ™‚ï¼‰
âœ” æ¨™é¡Œæˆ–å…§æ–‡åªè¦æåˆ°å…‰å¯¶ç§‘/å…‰å¯¶/2301 å°±ç®—ä¸€å‰‡
âœ” ç›´æ¥æŠ“å– Yahoo è‚¡å¸‚å€‹è‚¡æ–°èé é¢ (2301.TW)
âœ” ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ GOOGLE_APPLICATION_CREDENTIALS æŒ‡å‘ Firebase é‡‘é‘° JSON æª”
"""

import os
import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup, XMLParsedAsHTMLWarning
import warnings
import firebase_admin
from firebase_admin import credentials, firestore

warnings.filterwarnings("ignore", category=XMLParsedAsHTMLWarning)

HEADERS = {'User-Agent': 'Mozilla/5.0'}

# ----- Firestore åˆå§‹åŒ– -----
cred = credentials.Certificate(os.environ["GOOGLE_APPLICATION_CREDENTIALS"])
firebase_admin.initialize_app(cred)
db = firestore.client()

# ----- æ™‚é–“éæ¿¾ï¼ˆ72 å°æ™‚ï¼‰ -----
def is_recent(published_time, hours=72):
    now = datetime.now().astimezone()
    return (now - published_time) <= timedelta(hours=hours)

# ----- æŠ“æ–‡ç« å…§å®¹ï¼ˆå¯é¸ï¼‰ -----
def fetch_article_content(url):
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        paragraphs = soup.select('article p') or soup.select('p')
        text = "\n".join(p.get_text(strip=True) for p in paragraphs)
        return text[:1500] + ('...' if len(text) > 1500 else '')
    except Exception as e:
        return ""

# ----- é—œéµå­—åˆ¤æ–·ï¼ˆä¸ä¸€å®šéœ€è¦ï¼Œä½†ä¿ç•™ï¼‰ -----
def contains_keyword(title, content):
    keywords = ["å…‰å¯¶ç§‘", "2301", "å…‰å¯¶"]
    text = (title + " " + content)
    return any(k in text for k in keywords)

# =============================
#  Yahoo è‚¡å¸‚ â€” å…‰å¯¶ç§‘æ–°èæŠ“å–
# =============================
def fetch_yahoo_stock_news():
    print("ğŸ“¡ æŠ“å– Yahoo è‚¡å¸‚ â€” å…‰å¯¶ç§‘æ–°è")
    url = "https://tw.stock.yahoo.com/quote/2301.TW/news"
    r = requests.get(url, headers=HEADERS, timeout=10)
    soup = BeautifulSoup(r.text, 'html.parser')

    news_list = []
    seen = set()

    # æ¯æ¢æ–°èé€šå¸¸åŒ…åœ¨ <li> æˆ– <div>ï¼Œå¯é€éæ¨™é¡Œ h3 + a ä¾†æŠ“
    for a in soup.select("a.js-content-viewer, a[href^='/news/'], li a"):
        title = a.get_text(strip=True)
        if not title or title in seen:
            continue
        seen.add(title)

        href = a.get("href")
        if not href:
            continue
        # å®Œæ•´é€£çµ
        if href.startswith("/"):
            href = "https://tw.stock.yahoo.com" + href

        # è©¦è‘—æ“·å–æ™‚é–“ï¼ˆæœ‰äº›åœ¨ç›¸åŒ list item, åœ¨ time æˆ– span è£¡ï¼‰
        parent = a.find_parent()
        time_tag = None
        if parent:
            time_tag = parent.select_one("time") or parent.select_one("span[class*='C(#959595)']")

        published_dt = None
        if time_tag and time_tag.has_attr("datetime"):
            published_dt = datetime.fromisoformat(
                time_tag["datetime"].replace("Z", "+00:00")
            ).astimezone()
        else:
            # å¦‚æœæ²’æœ‰ datetime attributeï¼Œè©¦ parse text å¦‚ "2025/12/08 14:30"
            t = time_tag.get_text(strip=True) if time_tag else ""
            try:
                published_dt = datetime.strptime(t, "%Y/%m/%d %H:%M").astimezone()
            except:
                pass

        # å¦‚æœæ‹¿ä¸åˆ°æ™‚é–“ï¼Œå°±ç•¥é
        if not published_dt or not is_recent(published_dt):
            continue

        # æŠ“å…§å®¹ï¼ˆå¯é¸ï¼Œå¯åŠ ä¹Ÿå¯ä¸åŠ ï¼‰
        content = fetch_article_content(href)

        # é—œéµå­—éæ¿¾ï¼ˆå¯è¦–æƒ…æ³ç§»é™¤ï¼‰
        if not contains_keyword(title, content):
            # è‹¥ä¸éœ€è¦å…§æ–‡éæ¿¾ï¼Œå¯è¨»è§£æ‰é€™è¡Œ
            # continue
            pass

        news_list.append({
            "title": title,
            "url": href,
            "content": content,
            "published_time": published_dt,
            "source": "Yahoo è‚¡å¸‚"
        })

    return news_list

# =============================
# Firestore å„²å­˜ï¼ˆæ¸…ç©ºèˆŠè³‡æ–™ï¼‰
# =============================
def save_news(news_list):
    doc_id = datetime.now().strftime("%Y%m%d")
    ref = db.collection("NEWS_LiteOn").document(doc_id)

    data = {}
    for i, n in enumerate(news_list, 1):
        data[f"news_{i}"] = {
            "title": n["title"],
            "url": n["url"],
            "content": n["content"],
            "published_time": n["published_time"].strftime("%Y-%m-%d %H:%M:%S"),
            "source": n["source"]
        }

    ref.set(data, merge=False)
    print(f"âœ… å·²æ¸…ç©ºä¸¦å­˜å…¥ Firestoreï¼šNEWS_LiteOn/{doc_id}")

# =============================
# ä¸»ç¨‹å¼
# =============================
if __name__ == "__main__":
    yahoo_news = fetch_yahoo_stock_news()
    print(f"ğŸ” å…±æŠ“åˆ° {len(yahoo_news)} å‰‡å…‰å¯¶ç§‘è‚¡å¸‚æ–°èï¼ˆ3 å¤©å…§ï¼‰")
    if yahoo_news:
        save_news(yahoo_news)
    print("ğŸ‰ å…‰å¯¶ç§‘è‚¡å¸‚æ–°èæŠ“å–å®Œæˆï¼")
