# -*- coding: utf-8 -*-
"""
å¤šå…¬å¸æ–°èæŠ“å–ç¨‹å¼ï¼ˆå°ç©é›» + é´»æµ· + è¯é›»ï¼‰
ç‰ˆæœ¬ï¼šv7-huggingfaceï¼ˆembedding ç‰ˆ / Yahoo å¼·åŒ–ç‰ˆï¼‰
------------------------------------------------------
âœ” Yahoo æ–°ç‰ˆ HTML çµæ§‹å®Œæ•´æ”¯æ´ï¼ˆ2025ï¼‰
âœ” Firestore åªç”¨æ—¥æœŸç•¶ ID
âœ” å„²å­˜æ–°è title + content + æ¼²è·Œ + embedding
âœ” Hugging Face å…è²» Embedding API
âœ” æ–°èæ™‚é–“è§£æï¼ŒåªæŠ“ 36 å°æ™‚å…§æ–°è
"""

import os
import time
import json
import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup, XMLParsedAsHTMLWarning
import warnings
import firebase_admin
from firebase_admin import credentials, firestore
import yfinance as yf

warnings.filterwarnings("ignore", category=XMLParsedAsHTMLWarning)

# ---------------------- è¨­å®š ---------------------- #
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'
}

HF_API_URL = "https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2"
HF_TOKEN = os.environ.get("HF_TOKEN")

if not HF_TOKEN:
    raise ValueError("âš ï¸ æ‰¾ä¸åˆ° HF_TOKENï¼Œè«‹åœ¨ GitHub Secrets è¨­å®šï¼")

HF_HEADERS = {"Authorization": f"Bearer {HF_TOKEN}"}

# Firestore åˆå§‹åŒ–
key_dict = json.loads(os.environ["NEWS"])
cred = credentials.Certificate(key_dict)
firebase_admin.initialize_app(cred)
db = firestore.client()

ticker_map = {"å°ç©é›»": "2330.TW", "é´»æµ·": "2317.TW", "è¯é›»": "2303.TW"}

# ---------------------- æ™‚é–“éæ¿¾ ---------------------- #
def is_recent(published_time, hours=36):
    """åˆ¤æ–·æ–°èæ˜¯å¦åœ¨æœ€è¿‘ X å°æ™‚å…§"""
    now = datetime.now().astimezone()
    return (now - published_time) <= timedelta(hours=hours)

# ---------------------- è‚¡åƒ¹æ¼²è·Œ ---------------------- #
def fetch_stock_change(stock_name):
    ticker = ticker_map.get(stock_name)
    if not ticker: return "ç„¡è³‡æ–™"
    try:
        df = yf.Ticker(ticker).history(period="2d")
        if len(df) < 2: return "ç„¡è³‡æ–™"
        last = df['Close'].iloc[-1]
        prev = df['Close'].iloc[-2]
        diff = last - prev
        pct = diff / prev * 100
        sign = "+" if diff >= 0 else ""
        return f"{sign}{diff:.2f} ({sign}{pct:.2f}%)"
    except:
        return "ç„¡è³‡æ–™"

def add_price_change(news_list, stock_name):
    change = fetch_stock_change(stock_name)
    for n in news_list:
        n["price_change"] = change
    return news_list

# ---------------------- Embedding ---------------------- #
def generate_embedding(text):
    if not text: return []
    try:
        res = requests.post(
            HF_API_URL,
            headers=HF_HEADERS,
            json={"inputs": text[:1000]},
            timeout=20
        )
        data = res.json()
        if isinstance(data, list):
            return data
    except:
        pass
    return []

# ---------------------- æ–‡ç« å…§æ–‡ ---------------------- #
def fetch_article_content(url, source):
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')

        # Yahoo æ–°ç‰ˆï¼ˆ2025ï¼‰
        if source == 'yahoo':
            bdys = soup.find("div", {"class": "caas-body"})
            if bdys:
                paragraphs = bdys.find_all(["p", "h2"])
            else:
                paragraphs = soup.find_all("p")

        else:
            paragraphs = soup.find_all("p")

        text = "\n".join([
            p.get_text(strip=True)
            for p in paragraphs if len(p.get_text(strip=True)) > 40
        ])

        return text[:1500] + ('...' if len(text) > 1500 else '')
    except:
        return "ç„¡æ³•å–å¾—æ–°èå…§å®¹"

# ---------------------- Yahoo æ–°èï¼ˆå…¨ä¿®æ­£ï¼‰ ---------------------- #
def fetch_yahoo_news(keyword="å°ç©é›»", limit=30):
    print(f"\nğŸ“¡ Yahooï¼š{keyword}")
    base = "https://tw.news.yahoo.com"
    url = f"{base}/search?p={keyword}&sort=time"

    news_list, seen = [], set()

    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')

        # 2025 Yahoo ä¸»è¦é¸æ“‡å™¨
        items = soup.select("li.js-stream-content")                 # ä¸»è¦
        items += soup.select("div.SerpHoverCard")                   # éƒ¨åˆ†æœå°‹çµæœ
        items += soup.select("h3 a")                                # fallback

        for item in items:
            if len(news_list) >= limit: break

            # æ¨™é¡Œ
            a = item.find("a")
            if not a: continue

            title = a.get_text(strip=True)
            if not title or title in seen: continue
            seen.add(title)

            href = a.get("href")
            if href and not href.startswith("http"):
                href = base + href

            # å–å¾—æ–‡ç« æ™‚é–“
            try:
                art = requests.get(href, headers=HEADERS)
                s2 = BeautifulSoup(art.text, 'html.parser')
                time_tag = s2.find("time")
                if not time_tag or not time_tag.has_attr("datetime"):
                    continue
                published = datetime.fromisoformat(
                    time_tag["datetime"].replace("Z", "+00:00")
                ).astimezone()
                if not is_recent(published, 36):
                    continue
            except:
                continue

            # å…§æ–‡
            content = fetch_article_content(href, 'yahoo')

            news_list.append({
                "title": title,
                "content": content,
                "published_time": published
            })

    except Exception as e:
        print(f"Yahoo æŠ“å–éŒ¯èª¤ï¼š{e}")

    return news_list

# ---------------------- Firestore ---------------------- #
def save_news(news_list, collection):
    doc_id = datetime.now().strftime("%Y%m%d")
    ref = db.collection(collection).document(doc_id)

    data = {}
    for i, n in enumerate(news_list, 1):
        emb = generate_embedding(n.get("content", ""))
        data[f"news_{i}"] = {
            "title": n["title"],
            "price_change": n["price_change"],
            "content": n["content"],
            "embedding": emb,
            "published_time": n["published_time"].strftime("%Y-%m-%d %H:%M")
        }

    ref.set(data)
    print(f"âœ… Firestore å„²å­˜å®Œæˆï¼š{collection}/{doc_id}")

# ---------------------- ä¸»ç¨‹å¼ ---------------------- #
if __name__ == "__main__":

    # å°ç©é›»
    tsmc = fetch_yahoo_news("å°ç©é›»", 30)
    if tsmc:
        tsmc = add_price_change(tsmc, "å°ç©é›»")
        save_news(tsmc, "NEWS")

    # é´»æµ·
    fox = fetch_yahoo_news("é´»æµ·", 30)
    if fox:
        fox = add_price_change(fox, "é´»æµ·")
        save_news(fox, "NEWS_Foxxcon")

    # è¯é›»
    umc = fetch_yahoo_news("è¯é›»", 30)
    if umc:
        umc = add_price_change(umc, "è¯é›»")
        save_news(umc, "NEWS_UMC")

    print("\nğŸ‰ å…¨éƒ¨æ–°èæŠ“å–å®Œæˆï¼")
