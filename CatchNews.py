# -*- coding: utf-8 -*-
"""
å…‰å¯¶ç§‘æ–°èæŠ“å–ï¼ˆYahoo æœå°‹ + é‰…äº¨å…¨æ–‡ï¼‰+ Firestore å¯«å…¥
âœ” æŠ“æ¨™é¡Œ
âœ” è‡ªå‹•è§£è½‰å€ï¼ˆYahoo redirectï¼‰
âœ” æŠ“æ–°èå…¨æ–‡
âœ” å¯«å…¥ Firestoreï¼Œä¸å­˜ link
"""

import os
import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import firebase_admin
from firebase_admin import credentials, firestore


# -----------------------------
# Firestore åˆå§‹åŒ–
# -----------------------------
if not firebase_admin._apps:
    cred = credentials.Certificate(os.environ["GOOGLE_APPLICATION_CREDENTIALS"])
    firebase_admin.initialize_app(cred)

db = firestore.client()

COLL_NAME = "NEWS_LiteOn"
KEYWORDS = ["å…‰å¯¶ç§‘", "å…‰å¯¶", "2301"]
MAX_HOURS = 72


def in_range(dt):
    return (datetime.now() - dt).total_seconds() <= MAX_HOURS * 3600


# ----------------------------------------------------------
# è§£é–‹ Yahoo è½‰å€ r.search.yahoo.com â†’ çœŸæ­£æ–‡ç« é 
# ----------------------------------------------------------
def resolve_redirect(url):
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, allow_redirects=True, timeout=10)
        return r.url
    except:
        return url


# ----------------------------------------------------------
# æŠ“ Yahoo æ–°èå…§æ–‡
# ----------------------------------------------------------
def fetch_yahoo_article(url):
    try:
        resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")

        paras = soup.select("div.caas-body p")
        if not paras:
            return ""

        text = "\n".join([p.get_text(strip=True) for p in paras])
        return text

    except:
        return ""


# ----------------------------------------------------------
# Yahoo æœå°‹é 
# ----------------------------------------------------------
def fetch_yahoo_search():
    print("ğŸ“¡ æŠ“å– Yahoo æœå°‹é â€¦")

    url = "https://tw.news.search.yahoo.com/search?p=å…‰å¯¶ç§‘"
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers, timeout=10)
    soup = BeautifulSoup(resp.text, "html.parser")

    results = []

    items = soup.select("div.NewsArticle")
    for n in items:
        title_tag = n.select_one("h4 > a")
        if not title_tag:
            continue

        title = title_tag.get_text(strip=True)
        raw_link = title_tag["href"]

        # é—œéµå­—éæ¿¾
        if not any(k in title for k in KEYWORDS):
            continue

        # æ™‚é–“
        t = n.select_one("span.s-time")
        pub = parse_relative_time(t.get_text(strip=True)) if t else datetime.now()
        if not in_range(pub):
            continue

        # è§£è½‰å€
        real_url = resolve_redirect(raw_link)

        # æŠ“å…§æ–‡
        content = fetch_yahoo_article(real_url)

        results.append({
            "title": title,
            "content": content,
            "time": pub.strftime("%Y-%m-%d %H:%M"),
            "source": "Yahoo"
        })

    print(f"âœ” Yahoo æœå°‹æŠ“åˆ° {len(results)} å‰‡ï¼ˆå·²æŠ“å…¨æ–‡ï¼‰")
    return results


def parse_relative_time(text):
    now = datetime.now()
    try:
        if "åˆ†é˜å‰" in text:
            return now - timedelta(minutes=int(text.replace(" åˆ†é˜å‰", "")))
        if "å°æ™‚å‰" in text:
            return now - timedelta(hours=int(text.replace(" å°æ™‚å‰", "")))
        if "å¤©å‰" in text:
            return now - timedelta(days=int(text.replace(" å¤©å‰", "")))
    except:
        pass
    return now


# ----------------------------------------------------------
# é‰…äº¨ç¶²å…¨æ–‡æŠ“å–
# ----------------------------------------------------------
def fetch_cnyes():
    print("ğŸ“¡ æŠ“å– é‰…äº¨ç¶²â€¦")

    url = "https://news.cnyes.com/search?keyword=å…‰å¯¶ç§‘"
    resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(resp.text, "html.parser")

    results = []
    items = soup.select("a._1Zdp")

    for n in items:
        title = n.get_text(strip=True)
        link = "https://news.cnyes.com" + n.get("href", "")

        if any(k in title for k in KEYWORDS):
            content = fetch_cnyes_article(link)

            results.append({
                "title": title,
                "content": content,
                "time": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "source": "Cnyes"
            })

    print(f"âœ” é‰…äº¨ç¶²æŠ“åˆ° {len(results)} å‰‡ï¼ˆå·²æŠ“å…¨æ–‡ï¼‰")
    return results


def fetch_cnyes_article(url):
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(r.text, "html.parser")
        paras = soup.select("article p")
        return "\n".join([p.get_text(strip=True) for p in paras])
    except:
        return ""


# ----------------------------------------------------------
# Firestore å¯«å…¥
# ----------------------------------------------------------
def write_to_firestore(news_list):
    today = datetime.now().strftime("%Y%m%d")
    doc_ref = db.collection(COLL_NAME).document(today)

    doc_ref.set({"news_list": news_list}, merge=True)

    print(f"ğŸ”¥ Firestore å·²å¯«å…¥ â†’ {COLL_NAME}/{today}")
    print(f"ğŸ“¦ å…± {len(news_list)} å‰‡æ–°èï¼ˆå«å…¨æ–‡ï¼‰")


# ----------------------------------------------------------
# ä¸»æµç¨‹
# ----------------------------------------------------------
def main():
    yahoo = fetch_yahoo_search()
    cnyes = fetch_cnyes()

    all_news = yahoo + cnyes

    if not all_news:
        print("âš ï¸ æ²’æœ‰æ–°èå¯å¯«å…¥ Firestore")
        return

    write_to_firestore(all_news)


if __name__ == "__main__":
    main()
